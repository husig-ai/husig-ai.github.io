<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Husig.ai</title>
    <link>https://husig.ai/posts/</link>
    <description>Recent content in Posts on Husig.ai</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Jun 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://husig.ai/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[Paper Exploration] Train Once, Test Anywhere: Zero-Shot Learning for Text Classification</title>
      <link>https://husig.ai/posts/zero-shot-classification/</link>
      <pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://husig.ai/posts/zero-shot-classification/</guid>
      <description>[Paper Exploration] Train Once, Test Anywhere: Zero-Shot Learning for Text Classification Author: Pushpankar Kumar Pushp, Muktabh Mayank Srivastava&#xA;Published on 2017&#xA;Abstract Zero-shot Learners are models capable of predicting unseen classes. In this work, we propose a Zero-shot Learning approach for text categorization. Our method involves training model on a large corpus of sentences to learn the relationship between a sentence and embedding of sentence&amp;rsquo;s tags. Learning such relationship makes the model generalize to unseen sentences, tags, and even new datasets provided they can be put into same embedding space.</description>
    </item>
    <item>
      <title>[Paper Exploration] Adam: A Method for Stochastic Optimization</title>
      <link>https://husig.ai/posts/adam/</link>
      <pubDate>Tue, 19 Mar 2024 00:00:00 +0000</pubDate>
      <guid>https://husig.ai/posts/adam/</guid>
      <description>[Paper Exploration] Adam: A Method for Stochastic Optimization Author: Diederik P. Kingma, Jimmy Ba&#xA;Published on 2014&#xA;Abstract We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters.</description>
    </item>
    <item>
      <title>[Paper Exploration] Statistical Modeling: The Two Cultures</title>
      <link>https://husig.ai/posts/statistical_modelling_two_cultures/</link>
      <pubDate>Thu, 22 Feb 2024 00:00:00 +0000</pubDate>
      <guid>https://husig.ai/posts/statistical_modelling_two_cultures/</guid>
      <description>[Paper Exploration] Statistical Modeling: The Two Cultures Abstract There are two cultures in the use of statistical modeling to reach conclusions from data. One assumes that the data are generated by a given stochastic data model. The other uses algorithmic models and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems.</description>
    </item>
    <item>
      <title>[Paper Exploration] SMOTE: Synthetic Minority Over-sampling Technique</title>
      <link>https://husig.ai/posts/smote_paper_exploration/</link>
      <pubDate>Thu, 25 Jan 2024 00:00:00 +0000</pubDate>
      <guid>https://husig.ai/posts/smote_paper_exploration/</guid>
      <description>[Paper Exploration] SMOTE: Synthetic Minority Over-sampling Technique&amp;quot; Author: Nitesh V. Chawla, Kevin W. Bowyer, Lawrence O. Hall, W. Philip Kegelmeyer&#xA;Published on 9 Jun 2011&#xA;Abstract An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of “normal” examples with only a small percentage of “abnormal” or “interesting” examples.</description>
    </item>
    <item>
      <title>[Paper Exploration] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
      <link>https://husig.ai/posts/transformers_for_image_paper_exploration/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      <guid>https://husig.ai/posts/transformers_for_image_paper_exploration/</guid>
      <description>[Paper Exploration] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale&amp;quot; Authors: Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby&#xA;Published as a conference paper at ICLR 2021&#xA;Abstract While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place.</description>
    </item>
    <item>
      <title>[Paper Exploration] A Unified Approach to Interpreting Model Predictions</title>
      <link>https://husig.ai/posts/shap_exploration/</link>
      <pubDate>Thu, 07 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://husig.ai/posts/shap_exploration/</guid>
      <description>[Paper Exploration] A Unified Approach to Interpreting Model Predictions Paper Authors: Scott M. Lundberg, Su-In Lee&#xA;Code: https://github.com/shap/shap&#xA;Original Paper:&#xA;Exploration Problem Understanding model predictions is crucial for many applications. However, complex models, like ensemble or deep learning models, (while they usually achieve high accuracy) are generally difficult to interpret. Existing interpretation methods lack clarity about their relationships and preferences. Proposed Solution by Authors Introduce a unified framework called SHAP (SHapley Additive exPlanations) for interpreting predictions.</description>
    </item>
  </channel>
</rss>
