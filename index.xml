<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Husig.ai</title>
    <link>http://localhost:1313/</link>
    <description>Recent content in Posts on Husig.ai</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Nov 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI Solutions &amp; Partnerships Associate</title>
      <link>http://localhost:1313/careers/ai_partnership_and_growth_associate/</link>
      <pubDate>Thu, 13 Nov 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/careers/ai_partnership_and_growth_associate/</guid>
      <description>&lt;p&gt;We’re looking for a technically curious and people-oriented individual who wants to grow at the intersection of AI, data, and business.&lt;/p&gt;&#xA;&lt;p&gt;As an AI Solutions &amp;amp; Partnerships Associate, you’ll help connect HuSig’s advanced AI capabilities with organizations that can benefit from them. This role is ideal for someone with a background in computer science, data, or software who wants to move into solutions consulting, sales engineering, or partnerships — blending technical understanding with client interaction and problem-solving.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Paper Exploration] Adam: A Method for Stochastic Optimization</title>
      <link>http://localhost:1313/posts/adam/</link>
      <pubDate>Thu, 19 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/adam/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Author: Diederik P. Kingma, Jimmy Ba&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Published on 2014&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;We introduce Adam, an algorithm for &lt;strong&gt;first-order gradient-based optimization&lt;/strong&gt; of stochastic objective functions, based on adaptive estimates of &lt;strong&gt;lower-order moments&lt;/strong&gt;. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Paper Exploration] Deep Residual Learning for Image Recognition</title>
      <link>http://localhost:1313/posts/resnets/</link>
      <pubDate>Sat, 07 Dec 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/resnets/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Author: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Published on 2015&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers&amp;mdash;8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Paper Exploration] In-Depth Analysis of the Segment Anything Model (SAM)</title>
      <link>http://localhost:1313/posts/segment_anything/</link>
      <pubDate>Tue, 05 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/segment_anything/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Authors: Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo, Piotr Dollár, Ross Girshick&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Published on 2023&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;The &lt;strong&gt;Segment Anything Model (SAM)&lt;/strong&gt; was developed by Meta AI as a foundation model for image segmentation tasks. The goal of SAM is to create a universal model that can efficiently handle various segmentation tasks with minimal &lt;strong&gt;prompting&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://uploads-ssl.webflow.com/641bc1f4cda8707686f07277/643d06676d8d2025ce33b806_ezgif.com-video-to-gif-2.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;We introduce the Segment Anything (SA) project: a new task, model, and dataset for image segmentation. Using our efficient model in a data collection loop, we built the largest segmentation dataset to date (by far), with over 1 billion masks on 11M licensed and privacy respecting images. The model is designed and trained to be promptable, so it can transfer zero-shot to new image distributions and tasks. We evaluate its capabilities on numerous tasks and find that its zero-shot performance is impressive &amp;ndash; often competitive with or even superior to prior fully supervised results. We are releasing the Segment Anything Model (SAM) and corresponding dataset (SA-1B) of 1B masks and 11M images at this https URL to foster research into foundation models for computer vision.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Paper Exploration] Train Once, Test Anywhere: Zero-Shot Learning for Text Classification</title>
      <link>http://localhost:1313/posts/zero-shot-classification/</link>
      <pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/zero-shot-classification/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Author: Pushpankar Kumar Pushp, Muktabh Mayank Srivastava&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Published on 2017&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;!-- raw HTML omitted --&gt;&#xA;&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Zero-shot Learners are models capable of predicting unseen classes. In this work, we propose a Zero-shot Learning approach for text categorization. Our method involves training model on a large corpus of sentences to learn the relationship between a sentence and embedding of sentence&amp;rsquo;s tags. Learning such relationship makes the model generalize to unseen sentences, tags, and even new datasets provided they can be put into same embedding space. The model learns to predict whether a given sentence is related to a tag or not; unlike other classifiers that learn to classify the sentence as one of the possible classes. We propose three different neural networks for the task and report their accuracy on the test set of the dataset used for training them as well as two other standard datasets for which no retraining was done. We show that our models generalize well across new unseen classes in both cases. Although the models do not achieve the accuracy level of the state of the art supervised models, yet it evidently is a step forward towards general intelligence in natural language processing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Paper Exploration] Statistical Modeling: The Two Cultures</title>
      <link>http://localhost:1313/posts/statistical_modelling_two_cultures/</link>
      <pubDate>Thu, 22 Feb 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/statistical_modelling_two_cultures/</guid>
      <description>&lt;h2 id=&#34;abstract&#34;&gt;Abstract&lt;/h2&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;There are &lt;strong&gt;two cultures in the use of statistical modeling&lt;/strong&gt; to reach conclusions from data. One assumes that the data are generated by a given &lt;strong&gt;stochastic data model&lt;/strong&gt;. The other uses &lt;strong&gt;algorithmic models&lt;/strong&gt; and treats the data mechanism as unknown. The statistical community has been committed to the almost exclusive use of data models. This commitment has led to irrelevant theory, questionable conclusions, and has kept statisticians from working on a large range of interesting current problems. Algorithmic modeling, both in theory and practice, has developed rapidly in fields outside statistics. It can be used both on large complex data sets and as a more accurate and informative alternative to data modeling on smaller data sets. &lt;strong&gt;If our goal as a field is to use data to solve problems, then we need to move away from exclusive dependence on data models and adopt a more diverse set of tools.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Paper Exploration] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</title>
      <link>http://localhost:1313/posts/transformers_for_image_paper_exploration/</link>
      <pubDate>Mon, 18 Dec 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/posts/transformers_for_image_paper_exploration/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;Authors: Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Published as a conference paper at ICLR 2021&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;While the &lt;strong&gt;Transformer architecture&lt;/strong&gt; has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, &lt;strong&gt;attention&lt;/strong&gt; is either applied in conjunction with &lt;strong&gt;convolutional networks&lt;/strong&gt;, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image &lt;strong&gt;patches&lt;/strong&gt; can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (&lt;strong&gt;ImageNet&lt;/strong&gt;, CIFAR-100, VTAB, etc.), &lt;strong&gt;Vision Transformer (ViT)&lt;/strong&gt; attains excellent results compared to &lt;strong&gt;state-of-the-art&lt;/strong&gt; convolutional networks while requiring substantially fewer computational resources to train.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
